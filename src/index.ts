/**
 * Bootstrap core + server
 */

import "dotenv/config";
import path from "path";
import { EventBus } from "./core/eventBus";
import { VFS } from "./core/vfs";
import { PersistentEventBus, PersistentVFS } from "./core/storage";
import { ToolEngine } from "./core/tool-engine";
import { AgentCore } from "./core/agent/agentCore";
import { MockAdapter } from "./core/models/mockAdapter";
import { OpenAIAdapter } from "./core/models/openaiAdapter";

import { startServer } from "./server/index";
import { registerBuiltinTools } from "./core/tools/builtinTools";
import { initializeLogger, logger } from "./core/logger";
import { parseLogLevel, parseLogFormat } from "./core/logger/config";

async function main() {
  // Configuration
  const workspacePath = process.env.WORKSPACE_PATH || path.join(process.cwd(), "workspace");
  const projectId = process.env.PROJECT_ID || "default";

  // Initialize persistent storage
  const usePersistentStorage = process.env.PERSISTENT_STORAGE !== "false";
  
  let eventBus: EventBus;
  let vfs: VFS;

  if (usePersistentStorage) {
    console.log(`ðŸ“¦ Using persistent storage: ${workspacePath}/${projectId}`);
    
    // Persistent EventBus
    eventBus = await new PersistentEventBus({
      workspacePath,
      projectId,
    }).initialize();

    // Persistent VFS with max file size
    const maxFileSize = parseInt(process.env.VFS_MAX_FILE_BYTES || "10000000", 10);
    const persistentVFS = await new PersistentVFS(eventBus, {
      workspacePath,
      projectId,
      maxFileSize,
    }).initialize();
    vfs = persistentVFS as VFS;
  } else {
    console.log("ðŸ’¾ Using in-memory storage");
    const maxHistorySize = parseInt(process.env.EVENT_HISTORY_LIMIT || "10000", 10);
    eventBus = new EventBus({
      maxHistorySize,
      historyRetentionPolicy: "truncate",
    });
    vfs = new VFS(eventBus);
  }

  // Initialize logger with Pino
  const logLevel = parseLogLevel(process.env.LOG_LEVEL);
  const logFormat = parseLogFormat(process.env.LOG_FORMAT);

  const loggerInstance = initializeLogger(eventBus, {
    level: logLevel,
    format: logFormat,
    file: {
      enabled: process.env.LOG_FILE_ENABLED === "true",
      path: process.env.LOG_FILE_PATH || "./logs/arium.log",
    },
  });

  logger.info("ðŸš€ Starting Arium AI IDE Platform", {
    workspacePath,
    projectId,
    usePersistentStorage,
    logLevel,
    logFormat,
  });

  const toolEngine = new ToolEngine(eventBus);

  // Register all built-in tools
  registerBuiltinTools(toolEngine, vfs);

  // bootstrap file
  vfs.write("src/main.ts", "// hello world\n", "bootstrap");

  // Initialize model adapter
  // Priority: OpenAI > MockAdapter
  let modelAdapter;
  if (process.env.OPENAI_API_KEY) {
    console.log("ðŸ¤– Using OpenAI adapter");
    modelAdapter = new OpenAIAdapter({
      apiKey: process.env.OPENAI_API_KEY,
      model: process.env.OPENAI_MODEL || "gpt-4o-mini",
    }, eventBus);
  } else {
    console.log("ðŸŽ­ Using Mock adapter");
    console.log("   Set OPENAI_API_KEY to use OpenAI.");
    modelAdapter = new MockAdapter(eventBus);
  }

  const agent = new AgentCore(
    {
      id: "default-agent",
      model: modelAdapter,
      temperature: 0.0,
      maxTokens: 2048,
    },
    eventBus,
    toolEngine
  );

  console.log("");
  console.log("ðŸ”§ Initializing server...");
  await startServer({ agent, vfs, eventBus, toolEngine });
  console.log("âœ… Server initialization complete!");
}

main().catch(err => {
  console.error("Fatal error:", err);
  process.exit(1);
});

// Graceful shutdown
process.on("SIGINT", async () => {
  console.log("\nðŸ›‘ Shutting down gracefully...");
  // Close persistent storage if needed
  process.exit(0);
});

process.on("SIGTERM", async () => {
  console.log("\nðŸ›‘ Shutting down gracefully...");
  process.exit(0);
});

export {};
